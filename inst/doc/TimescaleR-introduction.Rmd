---
title: "Introduction to TimescaleR"
author: "Saurabh Aggrawal"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to TimescaleR}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE  # Don't evaluate code chunks since they require database connection
)
```

```{r setup}
library(TimescaleR)
```

## Overview

TimescaleR provides an interface to TimescaleDB, a time-series database built on PostgreSQL. The package enables R users to efficiently store, query, analyze, and visualize time-series data using TimescaleDB's specialized time-series functions.

## Key Features

- **Easy Connection Management**: Global and explicit connection handling
- **Hypertable Operations**: Create and manage TimescaleDB hypertables  
- **Time-Series Functions**: Time bucketing, aggregation, and specialized queries
- **Data Management**: Efficient data insertion, backup, and restoration
- **Continuous Aggregates**: Create and manage materialized views
- **Compression & Retention**: Automated data lifecycle management
- **Visualization**: Built-in plotting functions for time-series data

## Getting Started

### Prerequisites

Before using TimescaleR, you need:

1. A running TimescaleDB instance
2. Network access to the database
3. Valid credentials (username/password)

### Basic Connection

```{r}
# Initialize a global connection
init_connection(
  host = "localhost",
  port = 5432,
  db = "your_database",
  user = "your_username", 
  pass = "your_password",
  schema = "public"
)

# Check if connection is established
has_connection()
```

## Working with Time-Series Data

### Creating a Hypertable

```{r}
# Create sample time-series data
data <- data.frame(
  time = seq(as.POSIXct("2023-01-01"), by = "1 hour", length.out = 1000),
  sensor_id = rep(c("sensor_1", "sensor_2"), each = 500),
  temperature = rnorm(1000, 20, 5),
  humidity = rnorm(1000, 60, 10)
)

# Create a hypertable from the data
create_table_from_data_table(
  data, 
  "sensor_readings",
  as_hypertable = TRUE,
  time_column = "time"
)
```

### Time Bucketing Queries

Time bucketing is one of the most powerful features for time-series analysis:

```{r}
# Get hourly averages
hourly_avg <- time_bucket(
  table_name = "sensor_readings",
  time_column = "time", 
  bucket_interval = "1 hour",
  value_column = "temperature"
)

# Get daily averages grouped by sensor
daily_avg <- time_bucket(
  table_name = "sensor_readings",
  time_column = "time",
  bucket_interval = "1 day", 
  value_column = c("temperature", "humidity"),
  group_by = "sensor_id"
)
```

### Statistical Functions

```{r}
# Get the first and last readings
first_reading <- first_value(
  table_name = "sensor_readings",
  value_column = "temperature", 
  time_column = "time"
)

last_reading <- last_value(
  table_name = "sensor_readings",
  value_column = "temperature",
  time_column = "time" 
)

# Calculate moving averages
moving_avg <- moving_average(
  table_name = "sensor_readings",
  value_column = "temperature",
  time_column = "time",
  window_size = 7
)
```

## Advanced Features

### Continuous Aggregates

Continuous aggregates provide efficient materialized views that are automatically maintained:

```{r}
# Create a continuous aggregate for daily statistics
create_continuous_aggregate(
  view_name = "daily_sensor_stats",
  table_name = "sensor_readings", 
  time_column = "time",
  interval = "1 day",
  select_expr = "time_bucket('1 day', time) AS day,
                 sensor_id,
                 AVG(temperature) AS avg_temp,
                 MAX(temperature) AS max_temp,
                 MIN(temperature) AS min_temp,
                 AVG(humidity) AS avg_humidity"
)

# Add automatic refresh policy
add_refresh_policy("daily_sensor_stats", "1 hour")
```

### Data Lifecycle Management

```{r}
# Add compression policy - compress data older than 7 days
add_compression_policy("sensor_readings", "7 days")

# Add retention policy - drop data older than 1 year  
add_retention_policy("sensor_readings", "1 year")
```

### Backup and Restore

```{r}
# Backup a hypertable
backup_hypertable("sensor_readings", "/path/to/backup/")

# Restore from backup
restore_hypertable("sensor_readings", "/path/to/backup/")
```

## Data Visualization

TimescaleR includes built-in plotting functions:

```{r}
# Get some sample data
plot_data <- get_query("
  SELECT time, temperature 
  FROM sensor_readings 
  WHERE sensor_id = 'sensor_1' 
  ORDER BY time 
  LIMIT 100
")

# Create a time-series plot
plot <- plot_timeseries(
  data = plot_data,
  time_col = "time", 
  value_col = "temperature",
  title = "Temperature Over Time",
  color = "blue"
)

print(plot)
```

## Best Practices

### Connection Management

1. **Use Global Connections**: Initialize once with `init_connection()` and use throughout your session
2. **Always Close**: Use `close_connection()` when finished
3. **Check Status**: Use `has_connection()` to verify connection state

### Query Optimization

1. **Use Time Bucketing**: Leverage `time_bucket()` for efficient aggregations
2. **Limit Data**: Always use appropriate time ranges and LIMIT clauses
3. **Index Properly**: Ensure time columns are properly indexed

### Data Management

1. **Batch Inserts**: Use `insert_data_to_table()` with appropriate batch sizes
2. **Regular Maintenance**: Set up compression and retention policies
3. **Monitor Performance**: Use `monitor_hypertable_metrics()` to track performance

## Cleanup

Always clean up your connections:

```{r}
# Close the global connection
close_connection()
```

## More Information

For more detailed information:

- Function documentation: `help(package = "TimescaleR")`
- TimescaleDB documentation: https://docs.timescale.com/
- Package repository: https://github.com/saggrawal76/TimescaleR 